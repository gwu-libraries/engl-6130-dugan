

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Reading Machines &#8212; English 6130 (Dugan): Reading Machines</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'reading_writing_machines';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="References" href="bibliography.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="#">
  
  
  
  
  
    <p class="title logo__title">English 6130 (Dugan): Reading Machines</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1 current active">
                <a class="reference internal" href="#">
                    Reading Machines
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/gwu-libraries/engl-6130-dugan/blob/gh-pages/_sources/reading_writing_machines.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gwu-libraries/engl-6130-dugan" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gwu-libraries/engl-6130-dugan/issues/new?title=Issue%20on%20page%20%2Freading_writing_machines.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/reading_writing_machines.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Reading Machines</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-linguistic-unconscious-of-ai">Exploring the Linguistic Unconscious of AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-two-ways-of-thinking-about-computation">Introduction: Two ways of thinking about computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-kinds-of-coding">Two kinds of coding</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#programs-as-code-s">Programs as code(s)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#baby-steps-in-python">Baby steps in Python</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-text">Encoding text</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#representing-text-in-python">Representing text in Python</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-chance">Language &amp; chance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-long-history-of-code">The long history of code</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-spate-of-tedious-counting">A spate of tedious counting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-writing">Random writing</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-difference-a-space-makes">The difference a space makes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#law-abiding-numbers">Law-abiding numbers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-as-a-drunken-walk">Language as a drunken walk</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-tedious-counting">More tedious counting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-text">Preparing the text</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-table">Setting the table</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-writing">Automatic writing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-silly-walks">More silly walks</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-rabelaisian-chatbot">A Rabelaisian chatbot</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-drunken-was-our-walk">How drunken was our walk?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-lies-the-labor">Where lies the labor?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#further-experiments">Further experiments</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#carnival-intelligence">Carnival intelligence?</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="reading-machines">
<h1>Reading Machines<a class="headerlink" href="#reading-machines" title="Permalink to this heading">#</a></h1>
<section id="exploring-the-linguistic-unconscious-of-ai">
<h2>Exploring the Linguistic Unconscious of AI<a class="headerlink" href="#exploring-the-linguistic-unconscious-of-ai" title="Permalink to this heading">#</a></h2>
<section id="introduction-two-ways-of-thinking-about-computation">
<h3>Introduction: Two ways of thinking about computation<a class="headerlink" href="#introduction-two-ways-of-thinking-about-computation" title="Permalink to this heading">#</a></h3>
<p>The history of computing revolves around efforts to automate the human labor of computation.<a class="footnote-reference brackets" href="#id16" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> And in many narratives of this history, the algorithm plays a central role. By <em>algorithm</em>, I refer to methods of reducing complex calculations and other operations to explicit formal rules, rules that can be implemented with rigor and precision by purely mechanical or electronic means.<a class="footnote-reference brackets" href="#id20" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<p>But as a means of understanding Chat GPT and other forms of <a class="reference external" href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence">generative AI</a>, a consideration of algorithms only gets us so far. In fact, when it comes to the <a class="reference external" href="https://en.wikipedia.org/wiki/Large_language_model">large language models</a> that have captivated the public imagination, in order to make sense of their “unreasonable effectiveness,” we must attend to another strand of computing, one which, though bound up with the first, manifests distinct pressures and concerns.<a class="footnote-reference brackets" href="#id22" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> Instead of formal logic and mathematical proof, this strand draws on traditions of thinking about data, randomness, and probability. And instead of the prescription of (computational) actions, it aims at the description and prediction of (non-computational) aspects of the world.</p>
<p>A key moment in this tradition, in light of later developments, remains Claude Shannon’s* work on modeling the statistical structure of printed English (<span id="id4">[<a class="reference internal" href="bibliography.html#id3" title="C.E. Shannon. A mathematical theory of communication. The Bell System Technical Journal, 27(3-4):379–423, 623–656, July 1948. doi:10.1002/j.1538-7305.1948.tb01338.x.">Sha48</a>]</span>).  In this interactive document, we will use the <a class="reference external" href="https://www.python.org">Python programming language</a> to reproduce a couple of the experiments that Shannon* reported in his famous article, in the hopes of pulling back the curtain a bit on what seems to many (and not unreasonably) as evidence of a ghost in the machine. I, for one, do find many of these experiences haunting. But maybe the haunting doesn’t happen where we at first assume.<a class="footnote-reference brackets" href="#id24" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></p>
<p>The material that follows draws on and is inspired by my reading of Lydia Liu’s <em>The Freudian Robot</em>, one of the few works in the humanities that I’m aware of to deal with Shannon’s work in depth. See <span id="id6">[<a class="reference internal" href="bibliography.html#id5" title="Lydia He Liu. The Freudian robot: digital media and the future of the unconscious. University of Chicago Press, Chicago, 2010. ISBN 978-0-226-48682-6 978-0-226-48683-3.">Liu10</a>]</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>How to use this document (notebook)</p>
<p><strong>Notes on the format</strong></p>
<p>This document supports the aim, as articulated by Raley and Rhee, of “cultivating some degree of participatory and embodied expertise” as part of a critical perspective on AI <span id="id7">[<a class="reference internal" href="bibliography.html#id9" title="Rita Raley and Jennifer Rhee. Critical AI: A Field in Formation. American Literature, 95(2):185–204, June 2023. URL: https://doi.org/10.1215/00029831-10575021 (visited on 2024-01-15), doi:10.1215/00029831-10575021.">RR23</a>]</span>. Technically and rhetorically, the document belongs to a genre by now prevalent across many disciplines: the computational notebook. If you haven’t encountered this kind of document before, it represents a mixture of expository prose and computer code; the code is meant to be run (and in some instances, modified) by the user, to produce results that complement, illustrate, or otherwise support the exposition. Such notebooks most often evoke the model of empirical demonstration that derives its warrant from the natural and physical sciences; in relation to this model, the code allows the authors to “reproduce” an experiment (or portions of an experimental protocol) for the reader in “real” time (as opposed to merely reporting the results).<a class="footnote-reference brackets" href="#id26" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a></p>
<p>Using the Python language in this format allows us to both implement – and automate – Claude Shannon’s* methods of analyzing and manipulating text – methods that Shannon* originally deployed without the benefit of a computer. Python, like any other modern progamming language, makes these methods relatively trivial to perform. It is in that sense that I spoke of “reproducing” Shannon’s* “experiments” above. But I’ve also chosen to use Python in this particular format with Raley and Rhee’s call for a <em>critical</em> praxis in mind. Certainly, it would be possible to create a more seamless experience of the following, e.g., via a web app that would conceal the computational steps from the end user. But apps appeal to us because they perform this concealment, which fosters the impression that some “magic” is taking place behind the scenes. This aim of this document is, in part, to disrupt that concealment. Accordingly, I have included – alongside an exposition of Shannon’s* methods that goes into greater technical detail than that found in Liu’s book – annnotations of the Python code itself, which is meant to clarify how those methods get translated into a programming language. Reading these annotations is (I hope) not necessary for understanding the methods themselves. But for those interested in how code works, or for those with prior exposure to a programming language, these annotations may prove useful. With the exception of some introductory material, the annotations are marked off from the rest of the document in sections titled <code class="docutils literal notranslate"><span class="pre">Reading</span> <span class="pre">the</span> <span class="pre">code</span></code>.</p>
<hr class="docutils" />
<p><strong>Interacting with the document</strong></p>
<p>To get the most out of this document, you are encouraged to run the code where it appears in the executable sections below. Because Shannon’s* methods are stochastic, i.e., involving randomized selections among enumerated alternatives, the results of running much of this code will vary with each execution, and certain patterns will emerge clearly only over repeated executions. In addition, some code sections are designed to allow the reader/user to manipulate input values in order to assess their effect on the output.</p>
<p>In order to run the code, you will open a copy of this document in Google’s Colaboratory service. <a class="reference external" href="https://research.google.com/colaboratory/faq.html">Google Colab</a> is a freely available platform for programming with Python that requires no local installation and provides decent compute resources (memory and processing power).</p>
<p>To use this document in Colab, follow the steps below (or watch this short video):</p>
<ol class="arabic simple">
<li><p>Click the rocket icon <span class="fas fa-fa-rocket"></span> in the upper-right corner of this page.</p></li>
<li><p>Select the <code class="docutils literal notranslate"><span class="pre">Google</span> <span class="pre">Colab</span></code> option.</p></li>
<li><p>A new tab should open in your browser, displaying the content of this page but in the Colab interface.</p></li>
<li><p>Within that tab, click the button <code class="docutils literal notranslate"><span class="pre">Copy</span> <span class="pre">to</span> <span class="pre">Drive</span></code> from the menu at the top to create your own copy of the document (so that you can preserve any changes you make as well as the output from your interactions).</p></li>
</ol>
<a class="reference internal image-reference" href="_images/save-to-drive.png"><img alt="Button with the text &quot;Copy to Drive&quot; and the Google Drive symbol" src="_images/save-to-drive.png" style="width: 150px;" /></a>
<ol class="arabic simple" start="5">
<li><p>The Colab version of the document is backed by a running instance of the Python kernel (the program that runs Python progams), meaning that you can run the code and see the results in the Colab interface. To run any of the code sections, click the play icon to the left of that section, as in the image below.</p></li>
</ol>
<a class="reference internal image-reference" href="_images/play-button.png"><img alt="Python code with play button icon to the left; red arrow pointing to the play button." src="_images/play-button.png" style="width: 250px;" /></a>
<ol class="arabic simple" start="6">
<li><p>The logic of a programming language like Python is strictly linear. Running code sections out of order, or skipping a code section, will often result in errors, which will appear below the code section that triggered the error, in lieu of the expected output. If you start to encounter unexpected errors, go to the Colab menu at the top of the browser window and select <code class="docutils literal notranslate"><span class="pre">Runtime</span> <span class="pre">-</span> <span class="pre">Restart</span> <span class="pre">Session</span></code>. Then run each of the code sections in order, starting from the top of the document.</p></li>
</ol>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">Reading</span> <span class="pre">the</span> <span class="pre">code</span></code> sections, as well as footnotes and references, have been ommitted from the Colab version of this document in order to make the latter easier to use. So you may want to toggle back and forth between the two versions. (I apologize for that inconvenience – it’s a technical limitation I have not had time to address.)</p>
</div>
</section>
<section id="two-kinds-of-coding">
<h3>Two kinds of coding<a class="headerlink" href="#two-kinds-of-coding" title="Permalink to this heading">#</a></h3>
<p>Before we delve into our experiments, let’s clarify some terminology. In particular, what do we mean by <em>code</em>?</p>
<p>The demonstration below goes into a little more explicit detail, as far as the mechanics of Python are concerned, than the rest of this document. That’s intended to motivate the contrast to follow, between the kind of code we write in Python, and the kind of coding that Shannon’s* work deals with.</p>
<section id="programs-as-code-s">
<h4>Programs as code(s)<a class="headerlink" href="#programs-as-code-s" title="Permalink to this heading">#</a></h4>
<p>We imagine computers as machines that operate on 1’s and 0’s. In fact, the 1’s and 0’s are themselves an abstraction for human convenience: digital computation happens as a series of electronic pulses: switches that are either “on” or “off.” (Think of counting to 10 by flipping a light switch on and off 10 times.)</p>
<p>Every digital representation – everything that can be computed by a digital computer – must be encoded, ultimately, in this binary form.</p>
<p>But to make computers efficient for human use, many additional layers of abstraction have been developed on top of the basic binary layer. By virtue of using computers and smartphones, we are all familiar with the concept of an interface, which instantiates a set of rules prescribing how we are to interact with the device in order to accomplish well-defined tasks. These interactions get encoded down to the level of electronic pulses (and the results of the computation are translated back into the encoding of the interface).</p>
<p>A programming language is also an interface: a text-based one. It represents a code into which we can translate our instructions for computation, in order for those instructions to be encoded further for processing.</p>
</section>
<section id="baby-steps-in-python">
<h4>Baby steps in Python<a class="headerlink" href="#baby-steps-in-python" title="Permalink to this heading">#</a></h4>
<p>Let’s start with a single instruction. Run the following line of Python code by clicking the button,. You won’t see any output – that’s okay.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer_to_everything</span> <span class="o">=</span> <span class="mi">42</span>
</pre></div>
</div>
</div>
</div>
<p>In the encoding specified by the Python language, the equals sign (<code class="docutils literal notranslate"><span class="pre">=</span></code>) is an instruction that loosely translates to: “Store this value (on the right side) somewhere in memory, and give that location in memory the provided name (on the left side).” The following image presents one way of imagining what happens in response to this code (with the caveat that, ultimately, the letters and numbers are represented by their binary encoding).</p>
<a class="reference internal image-reference" href="_images/variable.png"><img alt="Shows the words &quot;answer to everything&quot; in one box, with an arrow pointing to a box in the middle, from which another arrow points to the number 42 in the third box. The first box is labeled &quot;name,&quot; the second &quot;variable,&quot; and the third, &quot;value.&quot;" src="_images/variable.png" style="width: 500px;" /></a>
<p>By running the previous line of code, we have created a <em>variable</em>, which maps the name <code class="docutils literal notranslate"><span class="pre">answer_to_everything</span></code> to the value <code class="docutils literal notranslate"><span class="pre">42</span></code>. We can use the variable to retrieve its value (for use in other parts of our program). Run the code below to see some output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">answer_to_everything</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">print()</span></code> <em>function</em> is a command in Python syntax that displays a value on the screen. Python’s syntax picks out the following elements:</p>
<ul class="simple">
<li><p>the name <code class="docutils literal notranslate"><span class="pre">print</span></code></p></li>
<li><p>the parentheses that follow it, which enclose the <em>argument</em></p></li>
<li><p>the argument itself, which in this case is a variable name (previously defined)</p></li>
</ul>
<p>These elements are perfectly arbitrary (in the Saussurean sense). This syntax was invented by the designers of the Python language, though they drew on conventions found in other programming languages. The point is that nothing about the Python command <code class="docutils literal notranslate"><span class="pre">print(answer_to_everything)</span></code> makes its operation transparent; to know what it does, you have to know the language (or, at least, be familiar with the conventions of programming languages more generally) – just as when learning to speak a foreign language, you can’t deduce much about the meaning of the words from the way they look or sound.</p>
<p>However, unlike so-called <em>natural languages</em>, even minor deviations in syntax will usually cause errors, and errors will usually bring the whole program to a crashing halt.<a class="footnote-reference brackets" href="#id27" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a></p>
<p>Run the code below – you should see an error message.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">answer_to_everythin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A misspelled variable name causes Python to abort its computation. Imagine if conversation ground to a halt whenever one of the parties mispronounced a word or used a malapropism!</p>
<p>I tend to say that Python is extremely literal. But of course, this is merely an analogy, and a loose one. There is no room for metaphor in programming languages, at least, not as far as the computation itself is concerned. The operation of a language like Python is determined by the algorithms used to implement it. Given the same input and the same conditions of operation, a given Python program should produce the same output every time. (If it does not, that’s usually considered a bug.)</p>
</section>
<section id="encoding-text">
<h4>Encoding text<a class="headerlink" href="#encoding-text" title="Permalink to this heading">#</a></h4>
<p>While <em>programming languages</em> are ways of encoding algorithms, the operation of the resulting <em>programs</em> does depend, in most cases, on more than just the algorithm itself. Programs depend on data. And in order to be used in computation, data must be encoded, too.</p>
<p>As an engineer at Bell Labs, Claude Shannon* wanted to find – mathematically – the most efficient means of encoding data for electronic transmission. Note that this task involves a rather different set of factors from those that influence the design of a programming language.</p>
<p>The designer of the language has the luxury of insisting on a programmer’s fidelity to the specified syntax. In working in Python, we have to write <code class="docutils literal notranslate"><span class="pre">print(42)</span></code>, exactly as written, in order to display the number <code class="docutils literal notranslate"><span class="pre">42</span></code> on the screen. if we forget the parentheses, for instance, the command won’t work. But when we talk on the phone (or via Zoom, etc.), it would certainly be a hassle if we had to first translate our words into a strict, fault-intolerant code like that of Python.</p>
<p>All the same, there is no digital (electronic) representation without encoding. To refer to the difference between these two types of codes, I am drawing a distinction between <em>algorithms</em> and <em>data</em>. Shannon’s* work illustrates the importance of this distinction, which remains relevant to any consideration of machine learning and generative AI.</p>
</section>
<section id="representing-text-in-python">
<h4>Representing text in Python<a class="headerlink" href="#representing-text-in-python" title="Permalink to this heading">#</a></h4>
<p>Before we turn to Shannon’s* experiments with English text, let’s look briefly at how Python represents text as data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_text</span> <span class="o">=</span> <span class="s2">&quot;Most noble and illustrious drinkers, and you thrice precious pockified blades (for to you, and none else, do I dedicate my writings), Alcibiades, in that dialogue of Plato&#39;s, which is entitled The Banquet, whilst he was setting forth the praises of his schoolmaster Socrates (without all question the prince of philosophers), amongst other discourses to that purpose, said that he resembled the Silenes.&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Running the code above creates a new variable, <code class="docutils literal notranslate"><span class="pre">a_text</span></code>, and assigns it to a <em>string</em> representing the first sentence from Francois Rabelais’ early Modern novel, <em>Gargantua and Pantagruel</em>. A string is the most basic way in Python of representing text, where “text” means anything that is not to be treated purely a numeric value.</p>
<p>Anything between quotation marks (either double <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code> or single <code class="docutils literal notranslate"><span class="pre">''</span></code>) is a string.</p>
<p>One problem with strings in Python (and other programming languages) is that they have very little structure. A Python string is a sequence of characters, where a <em>character</em> is a letter of a recognized alphabet, a punctuation mark, a space, etc. Each character is stored in the computer’s memory as a numeric code, and from that perspective, all characters are essentially equal. We can access a single character in a string by supplying its position. (Python counts characters in strings from left to right, starting with 0, not 1, for the first character.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_text</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can access a sequence of characters – here, the characters in positions 11 through 50.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_text</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can even divide the string into pieces, using the occurences of particular characters. The code below divides our text on the white space, returning a <em>list</em> (another Python construct) of smaller strings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The strings in the list above correspond, loosely, to the individual words in the sentence from Rabelais’ text. But Python really has no concept of “word,” neither in English, nor any other (natural) language.</p>
</section>
</section>
<section id="language-chance">
<h3>Language &amp; chance<a class="headerlink" href="#language-chance" title="Permalink to this heading">#</a></h3>
<p>It’s probably fair to say that when Shannon* was developing his mathematical approach to encoding information, the algorithmic ideal  dominated computational research in Western Europe and the United States. In previous decades, philosophers like Bertrand Russell and mathematicians like David Hilbert had sought to develop a formal approach to mathematical proof, an approach that, they hoped, would ultimately unify the scientific disciplines. The goal of such research was to identify a core set of axioms, or logical rules, in terms of which all other “rigorous” methods of thought could be expressed. In other words, to reduce to zero the uncertainty and ambiguity plaguing natural language as a tool for expression: to make language algorithmic.</p>
<p>Working within this tradition, Alan Turing had developed his model of what would become the digital computer.</p>
<p>But can language as humans use it be reduced to such formal rules? On the face of it, it’s easy to think not. However, that conclusion presents a problem for computation involving natural language, since the computer is, at bottom, a formal-rule-following machine. Shannon’s* work implicitly challenges the assumption that we need to resort to formal rules in order to deal with the uncertainty in language. Instead, he sought mathematical means for <em>quantifying</em> that uncertainty.<a class="footnote-reference brackets" href="#id28" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a>  And as Lydia Liu points out, that effort began with a set of observations about patterns in printed English texts.</p>
<section id="the-long-history-of-code">
<h4>The long history of code<a class="headerlink" href="#the-long-history-of-code" title="Permalink to this heading">#</a></h4>
<p>Of course, Shannon’s* insights do not begin with Shannon*. A long history predates him of speculation on what we might call the statistical features of language. Speculations of some practical urgency, given the even longer history of cryptographic communication in political, military, and other contexts.</p>
<p>In the 9th Century CE, the Arab mathematician and philosopher Al-Kindi composed a work on cryptography in which he applied the relative frequency of letters in Arabic to a method for decrypting coded text (<span id="id11">[<a class="reference internal" href="bibliography.html#id11" title="Lyle D. Broemeling. An Account of Early Statistical Inference in Arab Cryptology. The American statistician, 65(4):255–257, 2011. doi:10.1198/tas.2011.10191.">Bro11</a>]</span>). Al-Kindi, alongside his many other accomplishments, composed the earliest surviving analysis of this kind, which is a direct precursor of methods popular in the digital humanities (word frequency analysis), among other many other domains.</p>
<p>Closer yet to the hearts of digital humanists, the Russian mathematician Andrei Markov, in a 1913 address to the Russian Academy of Sciences, reported on the results of his experiment with Aleksandr Pushkin’s <em>Evegnii Onegin</em>: a statistical analysis of the occurrences of consonants and vowels in the first two chapters of Pushkin’s novel in verse (<span id="id12">[<a class="reference internal" href="bibliography.html#id12" title="A. A. Markov. An Example of Statistical Investigation of the Text \textit Eugene Onegin Concerning the Connection of Samples in Chains. Science in Context, 19(4):591–600, December 2006. URL: https://www.cambridge.org/core/product/identifier/S0269889706001074/type/journal_article (visited on 2024-02-05), doi:10.1017/S0269889706001074.">Mar06</a>]</span>). From the perspective of today’s large-language models, Markov improved on Al-Kindi’s methods by counting not just isolated occurrences of vowels or consonants, but co-occurences: that is, where a vowel follows a consonant, a consonant a vowel, etc. As a means of articulating the structure of a sequential process, Markov’s method generalizes into a powerful mathematical tool, to which he lends his name. We will see how Shannon* used <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain">Markov chains</a> shortly.</p>
</section>
<section id="a-spate-of-tedious-counting">
<h4>A spate of tedious counting<a class="headerlink" href="#a-spate-of-tedious-counting" title="Permalink to this heading">#</a></h4>
<p>First, however, let’s illustrate the more basic method, just to get a feel for its effectiveness.</p>
<p>We’ll take a text of sufficient length. Urquhart’s English translation of <em>Gargantual and Pantagruel</em>, in the Everyman’s Library edition, clocks in at 823 pages; that’s a decent sample. If we were following the methods used by Al-Kindi, Markov, or even Shannon* himself, we would proceed as follows:</p>
<ol class="arabic simple">
<li><p>Make a list of the letters of the alphabet on a sheet of paper.</p></li>
<li><p>Go through the text, letter by letter.</p></li>
<li><p>Beside each letter on your paper, make one mark each time you encounter that letter in the text.</p></li>
</ol>
<p>Fortunately for us, we can avail ourselves of a computer to do this work.</p>
<p>In the following sections of Python code, we download the Project Gutenberg edition of Rabelais’ novel, saving it to the computer as a text file. We can read the whole file into the computer’s memory as a single Python string. Then using a property of Python strings that allows us to <em>iterate</em> over them, we can automate the process of counting up the occurences of each character.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="n">urlretrieve</span><span class="p">(</span><span class="s2">&quot;https://www.gutenberg.org/cache/epub/1200/pg1200.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;gargantua.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;gargantua.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">g_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<ol class="arabic simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">from</span></code>…<code class="docutils literal notranslate"><span class="pre">import</span></code> statement (lines of Python code are called <em>statements</em>) loads some external code (i.e., code that wasn’t automatically loaded when we started our Python session) for use in retrieving data from the web.</p></li>
<li><p>This external code is in the form of a Python <em>function</em> called <code class="docutils literal notranslate"><span class="pre">urlretrieve()</span></code>. Like <code class="docutils literal notranslate"><span class="pre">print()</span></code> in the previous example, a Python function is recognizable by the parentheses following its name.</p></li>
<li><p>Within these parentheses, we can supply zero, one, or more <em>arguments</em>. Arguments are values or variables that the function will use to do some work. We can organize our code into functions in order to make it more easily reusable – even by others. I did not write the <code class="docutils literal notranslate"><span class="pre">urlretrieve</span></code> function – this code is merely importing and using it. Calling an external function in programming is a little like citing a source in writing: a way of building on others’ work.</p></li>
<li><p><em>Calling</em> the <code class="docutils literal notranslate"><span class="pre">urlretrieve()</span></code> function (what we’re doing here) doesn’t produce any <em>visible</em> output, but behind the scenes, it fetches the data at the URL (the first argument, between the first pair of quotation marks) and saves that data as a file (the name of which is provided as the second argument, <code class="docutils literal notranslate"><span class="pre">&quot;gargantua.txt&quot;</span></code>).</p></li>
<li><p>In the next section, I use another function, <code class="docutils literal notranslate"><span class="pre">open()</span></code>, to open the file, meaning to make it available in the computer’s memory for access. The <code class="docutils literal notranslate"><span class="pre">as</span> <span class="pre">f</span></code> part of that line indicates that the file, while it’s open, can be accessed via the variable <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p></li>
<li><p>In the indented part, I use the <code class="docutils literal notranslate"><span class="pre">read()</span></code> method to load the contents of the file into memory. using the variable <code class="docutils literal notranslate"><span class="pre">g_text</span></code>. Henceforth, the entirety of Rabelais’ text is available for use by reference to the <code class="docutils literal notranslate"><span class="pre">g_text</span></code> variable. (For the duration of this Python session, that is – if I close this browser tab, I’ll lose all the variables, etc., and will have to re-run the code to re-create them.)</p></li>
</ol>
<p><strong>Note on Python variables</strong></p>
<ul class="simple">
<li><p>Variable names in Python do <em>not</em> go inside quotation marks.</p></li>
<li><p>Variables are like variables in algebra: they are arbitrary names that stand for specified values.</p></li>
<li><p>They usually appear, when first used, either on the <em>left</em> side of an equals sign (<code class="docutils literal notranslate"><span class="pre">g_text</span> <span class="pre">=</span> <span class="pre">f.read()</span></code>) or inside the parentheses following a function call. That is how the variables acquire their values.</p></li>
<li><p>It’s worth reiterating: variable names (and function names, too) are arbitrary: i.e., it’s the programmer’s choice. In the code in this document, I’ve tried to create variable names that at least suggest what they refer to, but that’s just a stylistic convention for making code easier to read; it makes no difference to the computer.</p></li>
</ul>
</div>
<p>Running the code below uses the <code class="docutils literal notranslate"><span class="pre">len()</span></code> function to display the length – in characters – of a string.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">g_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The Project Gutenberg version of <em>Gargantua and Pantagruel</em> has close to a 2 million characters.</p>
<p>As an initial exercise, we can count the frequency with which each character appears. Run the following section of code to create a structure mapping each character to its frequency.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_characters</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">g_text</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">g_characters</span><span class="p">:</span>
        <span class="n">g_characters</span><span class="p">[</span><span class="n">character</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">g_characters</span><span class="p">[</span><span class="n">character</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Run the code below to reveal the frequencies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_characters</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<ul class="simple">
<li><p>Data structures in Python are often identified by punctuation marks. The curly braces in the output above indicate that the outermost structure is a <em>dictionary</em>, which is a mapping of <em>keys</em> to <em>values</em>. The keys are sort of like variable names, except that they go inside quotation marks.</p></li>
<li><p>Data structures in Python can contain other data structures. Our `g_characters_ dictionary ultimately consists of Python strings mapped to integers (a numeric data type in Python).</p></li>
<li><p>To create our dictionary of character frequencies, we use the following logic:</p>
<ol class="arabic simple">
<li><p>We create the variable <code class="docutils literal notranslate"><span class="pre">g_characters</span></code>, setting it to an empty dictionary (<code class="docutils literal notranslate"><span class="pre">{}</span></code>).</p></li>
<li><p>We loop over the <code class="docutils literal notranslate"><span class="pre">g_text</span></code> variable, which holds a string, i.e., a sequence of characters. The <code class="docutils literal notranslate"><span class="pre">for</span></code> keyword in Python allows us to access each element in a sequence (like a string) one at a time.</p></li>
<li><p>Each time through the loop, the current character will be assigned to the <code class="docutils literal notranslate"><span class="pre">character</span></code> variable.</p></li>
<li><p>In the code indented under the <code class="docutils literal notranslate"><span class="pre">for</span></code> line, we check to see whether we have encountered this particular character before (using the variable <code class="docutils literal notranslate"><span class="pre">character</span></code> to refer to it, just as one might solve for <code class="docutils literal notranslate"><span class="pre">x</span></code> in an algebraic equation).</p></li>
<li><p>If we have encountered this character already, we assume that it’s associated with a number in our <code class="docutils literal notranslate"><span class="pre">g_characters</span></code> dictionary, and we increment that number (just as if we were making another hash mark on a sheet of paper).</p></li>
<li><p>Otherwise, we add this character to <code class="docutils literal notranslate"><span class="pre">g_characters</span></code> and set the tally to 1 (since this is the first occurrence of that character).</p></li>
</ol>
</li>
</ul>
</div>
<p>Looking at the contents of <code class="docutils literal notranslate"><span class="pre">g_characters</span></code>, we can see that it consists of more than just the letters in standard <a class="reference external" href="https://en.wikipedia.org/wiki/Latin_script">Latin script</a>. There are punctuation marks, numerals, and other symbols, like <code class="docutils literal notranslate"><span class="pre">\n</span></code>, which represents a line break.</p>
<p>But if we look at the 10 most commonly occurring characters, with one exception, it aligns well with the <a class="reference external" href="https://en.wikipedia.org/wiki/Letter_frequency">relative frequency of letters in English</a> as reported from studying large textual corpora.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">sorted</span><span class="p">(</span><span class="n">g_characters</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<p>This last line code sacrifices clarity for brevity – a practice I will generally refrain from in this document. But it does illustrate how we can compose complex operations in Python out simpler elements – which is the fundamental practice of programming.</p>
<p>Here we sort our <code class="docutils literal notranslate"><span class="pre">g_characters</span></code> by the numeric elements (so the counts, not the characters), using the built-in <code class="docutils literal notranslate"><span class="pre">sorted</span></code> function, to which we provide the optional argument <code class="docutils literal notranslate"><span class="pre">reverse=True</span></code> to sort in descending order. Then in the square brackets at the end of the line, we look at the first 10 elements in that (now) sorted sequence.</p>
</div>
</section>
<section id="random-writing">
<h4>Random writing<a class="headerlink" href="#random-writing" title="Permalink to this heading">#</a></h4>
<p>At the heart of Shannon’s* method lies the notion of <em>random sampling</em>. It’s perhaps easiest to illustrate this concept before defining it.</p>
<p>Using more Python code, let’s compare what happens when we construct two random samples of the letters of the Latin script, one in which we select each letter with equal probability, and the other in which we weight our selections according to the frequency we have computed above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">choices</span>
<span class="n">alphabet</span> <span class="o">=</span> <span class="s2">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">choices</span><span class="p">(</span><span class="n">alphabet</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>The code above uses the <code class="docutils literal notranslate"><span class="pre">choices()</span></code> method to create a sample of 50 letters, where each letter is equally likely to appear in our sample. Imagine rolling a 26-sided die, with a different letter on each face, 50 times, writing down the letter that comes up on top each time.</p>
<p>Now let’s run this trial again, this time supplying the observed frequency of the letters in <em>Gargantual and Pantagruel</em> as weights to the sampling. (For simplicity’s sake, we first remove everything but the 26 lowercase letters of the Latin script: numbers, punctuation marks, spaces, letters with accent marks, etc.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_alpha_chars</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">g_characters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">alphabet</span><span class="p">:</span>
        <span class="n">g_alpha_chars</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>
<span class="n">letters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g_alpha_chars</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">g_alpha_chars</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">choices</span><span class="p">(</span><span class="n">letters</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Do you notice any difference between the two results? It depends to some extent on roll of the dice, since both selections are still random. But you might see <em>more</em> runs of letters in the second that resemble sequences you could expect in English, maybe even a word or two hiding in there.</p>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<ul class="simple">
<li><p>The line <code class="docutils literal notranslate"><span class="pre">print(&quot;&quot;.join(choices(alphabet,</span> <span class="pre">k=50)))</span></code> displays the result of using the <code class="docutils literal notranslate"><span class="pre">choices</span></code> function to take a random, evenly weighted sample of size <code class="docutils literal notranslate"><span class="pre">k</span></code>. Because <code class="docutils literal notranslate"><span class="pre">choices</span></code> returns a Python list (another data type), not a string, we use the <code class="docutils literal notranslate"><span class="pre">.join()</span></code> method to create a single string out of the 50 letters in our sample – just to make it more readable.</p></li>
<li><p>We use another <code class="docutils literal notranslate"><span class="pre">for</span></code> loop and an <code class="docutils literal notranslate"><span class="pre">if</span></code> statement to create a new dictionary, <code class="docutils literal notranslate"><span class="pre">g_alpha_chars</span></code>, to hold just the frequencies of those characters that can be found in the string called <code class="docutils literal notranslate"><span class="pre">alphabet</span></code> (previously defined).</p></li>
<li><p>Then we separate out the characters and their frequencies into two parallel lists. (We do this on account of the way <code class="docutils literal notranslate"><span class="pre">choices()</span></code> is defined to work.)</p></li>
<li><p>Finally, we use these two lists as arguments to <code class="docutils literal notranslate"><span class="pre">choices</span></code>, where the presence of the <code class="docutils literal notranslate"><span class="pre">weights</span></code> argument means that the sample will no longer be equally weighted, but that each character in <code class="docutils literal notranslate"><span class="pre">letters</span></code> will be selected with the frequency suppled in <code class="docutils literal notranslate"><span class="pre">weights</span></code>.</p></li>
</ul>
</div>
</section>
<section id="the-difference-a-space-makes">
<h4>The difference a space makes<a class="headerlink" href="#the-difference-a-space-makes" title="Permalink to this heading">#</a></h4>
<p>On Liu’s telling, one of Shannon’s* key innovations was his realization that in analyzing <em>printed</em> English, the <em>space between words</em> counts as a character. It’s the spaces that delimit words in printed text; without them, our analysis fails to account for word boundaries.</p>
<p>Let’s say what happens when we include the space character in our frequencies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_shannon_chars</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">g_characters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">alphabet</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="s2">&quot; &quot;</span><span class="p">:</span>
        <span class="n">g_shannon_chars</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>
<span class="n">letters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g_shannon_chars</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">weights</span><span class="o">=</span><span class="n">g_shannon_chars</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">choices</span><span class="p">(</span><span class="n">letters</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>It may not seem like much improvement, but now we’re starting to see sequences of recognizable “word length,” considering the average lengths of words in English.</p>
<p>But note that we haven’t so far actually tallied anything that would count as a word: we’re still operating exclusively at the level of individual characters or letters.</p>
</section>
<section id="law-abiding-numbers">
<h4>Law-abiding numbers<a class="headerlink" href="#law-abiding-numbers" title="Permalink to this heading">#</a></h4>
<p>To unpack what we’re doing a little more: when we make a <em>weighted</em> selection from the letters of the alphabet, using the frequencies we’ve observed, it’s equivalent to drawing letters out of a bag of Scrabble tiles, where different tiles appear in a different amounts. If there are 5 <code class="docutils literal notranslate"><span class="pre">e</span></code>’s in the bag but only 1 <code class="docutils literal notranslate"><span class="pre">z</span></code>, you might draw a <code class="docutils literal notranslate"><span class="pre">z</span></code>, but over time, you’re more likely to draw an <code class="docutils literal notranslate"><span class="pre">e</span></code>. And if you make repeated draws, recording the letter you draw each time before putting it back in the bag, your final tally of letters will usually have more <code class="docutils literal notranslate"><span class="pre">e</span></code>’s than <code class="docutils literal notranslate"><span class="pre">z</span></code>’s.</p>
<p>In probability theory, this expectation is called <a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_large_numbers">the law of large numbers</a>. It describes the fundamental intuition behind the utility of averages, as well as their limitation: sampling better approximates the mathematical average as the samples get larger, but in every case, we’re talking about behavior in the aggregate, not the individual case.</p>
</section>
</section>
<section id="language-as-a-drunken-walk">
<h3>Language as a drunken walk<a class="headerlink" href="#language-as-a-drunken-walk" title="Permalink to this heading">#</a></h3>
<p>How effectively can we model natural language using statistical means? It’s worth dwelling on the assumptions latent in this question. Parts of speech, word order, syntactic dependencies, etc: none of these classically linguistic entities come up for discussion in Shannon’s* article. Nor are there any claims therein about underlying structures of thought that might map onto grammatical or syntactic structures, such as we find in the Chomskian theory of <a class="reference external" href="https://en.wikipedia.org/wiki/Generative_grammar">generative grammar</a>. The latter theory remains squarely within the algorithmic paradigm: the search for formal rules or laws of thought.</p>
<p>Language, in Shannon’s* treatment, resembles a different kind of phenomena: biological populations, financial markets, or the weather. In each of these systems, it is taken as a given that there are simply too many variables at play to arrive at the kind of description that would even remotely resemble the steps of a formally logical proof. Rather, the systems are described, and attempts are made to predict their behavior over time, drawing on observable patterns held to be valid in the aggregate.</p>
<p>Whether the human linguistic faculty is best described in terms of formal, algorithmic rules, or as something else (emotional weather, perhaps), was not a question germane to Shannon’s* analysis. Inn the introduction to his 1948 article, he claims that the “semantic aspects of communication are irrelevant to the engineering problem” (i.e., the problem of devising efficient means of encoding messages, linguistic or otherwise). These “semantic aspects,” excluded from “the engineering problem,” return to haunt the scene of generative AI with a vengeance. But in order to set this scene, let’s return to Shannon’s* experiments.</p>
<p>Following Andrei Markov, Shannon* modeled printed English as a Markov chain: as a special kind of weighted selection where the weights of the current selection depend <em>only</em> on the immediately previous selection. A Markov chain is often called a <em>random walk</em>, though the conventional illustration is of a person who has had a bit too much to drink stumbling about. Observing such a situation, you might not be able to determine where the person is trying to go; all you can predict is that their next position will fall within stumbling distance of where they’re standing right now. Or if you prefer a less Rabelaisian metaphor, imagine threading your way among a host of puddles. With each step, you try to keep to dry land, but your path is likely to be anything but linear.</p>
<p>It turns out that Markov chains can be used to model lots of processes in the physical world. And they can be used to model language, too, as Claude Shannon* showed.</p>
<section id="more-tedious-counting">
<h4>More tedious counting<a class="headerlink" href="#more-tedious-counting" title="Permalink to this heading">#</a></h4>
<p>One way to construct such an analysis is as follows: represent your sample of text as a continuous string of characters. (As we’ve seen, that’s easy to do in Python.) Then “glue” it to another string, representing the same text, but with every character shifted to the left by one position. For example, the first several characters of the first sentence from <em>Gargantua and Pantagruel</em> would look like this:</p>
<a class="reference internal image-reference" href="_images/rabelais-1.png"><img alt="The text &quot;Most noble and illust&quot; is shown twice, one two consecutive lines, with each letter surrounded by a box. The second line is shifted to the left one character, so that the &quot;M&quot; of the first line appears above the &quot;o&quot; of the second line, etc." src="_images/rabelais-1.png" style="width: 500px;" /></a>
<p>With the exception of the dangling left-most and right-most characters, you now have a pair of strings that yield, for each position, a pair of characters. In the image below, the first few successive pairs are shown, along with the position of each pair of characters with respect to the “glued” strings.</p>
<a class="reference internal image-reference" href="_images/rabelais-2.png"><img alt="A table with the letters &quot;h,&quot; a space, &quot;o,&quot; &quot;e,&quot; and &quot;i&quot; along the top (column headers), and &quot;t,&quot; space, &quot;c,&quot; &quot;w,&quot; &quot;s,&quot; and &quot;g&quot; along the left-hand side (row labels), and numbers in the cells of the table." src="_images/rabelais-2.png" style="width: 500px;" /></a>
<p>These pairs are called bigrams. But in order to construct a Markov chain, we’re not just counting bigrams. Rather, we want to create what’s called a <em>transition table</em>: a table where we can look up a given character – the letter <code class="docutils literal notranslate"><span class="pre">e</span></code>, say – and then for any other character that can follow <code class="docutils literal notranslate"><span class="pre">e</span></code>, find the frequency with which it occurs in that position (i.e., following an <code class="docutils literal notranslate"><span class="pre">e</span></code>). If a given character never follows another character, its bigram doesn’t exist in the table.</p>
<p>Below are shown some of the most common bigrams in such a transition table created on the basis of <em>Gargantua and Pantagruel</em>.</p>
<a class="reference internal image-reference" href="_images/bigram-table.png"><img alt="The text &quot;Most noble and illust&quot; is shown as above, with the addition of alternating yellow and blue highlighting to identify pairs of letters, and numbers along the bottom, starting at 0." src="_images/bigram-table.png" style="width: 300px;" /></a>
</section>
<section id="preparing-the-text">
<h4>Preparing the text<a class="headerlink" href="#preparing-the-text" title="Permalink to this heading">#</a></h4>
<p>To simplify our analysis, first we’ll standardize the source text a bit. Removing punctuation and non-alphabetic characters, removing extra runs of white space and line breaks, and converting everything to lowercase will make patterns in the results easier to see (though it’s really sort of an aesthetic choice, and as I’ve suggested, Shannon’s* method doesn’t presuppose any essential difference between the letters of words and the punctuation marks that accompany them).</p>
<p>Run the two code sections below to clean the text of <em>Gargantua and Pantagruel</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalize_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Reduces the provided string to a string consisting of just alphabetic, lowercase characters from the Latin script and non-contiguous spaces.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">text_lower</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text_lower</span> <span class="o">=</span> <span class="n">text_lower</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">text_norm</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">text_lower</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">char</span> <span class="ow">in</span> <span class="s2">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">char</span> <span class="o">==</span> <span class="s2">&quot; &quot;</span> <span class="ow">and</span> <span class="n">text_norm</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">text_norm</span> <span class="o">+=</span> <span class="n">char</span>
    <span class="k">return</span> <span class="n">text_norm</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_text_norm</span> <span class="o">=</span> <span class="n">normalize_text</span><span class="p">(</span><span class="n">g_text</span><span class="p">)</span>
<span class="n">g_text_norm</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<p>The bulk of this code defines a new function, <code class="docutils literal notranslate"><span class="pre">normalize_text()</span></code>, which we can use to perform this procedure whenever we need to. The procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Create a lowercased version of the provided <code class="docutils literal notranslate"><span class="pre">text</span></code> argument, using the built-in <code class="docutils literal notranslate"><span class="pre">lower()</span></code> method.</p></li>
<li><p>Using the built-in <code class="docutils literal notranslate"><span class="pre">replace()</span></code> method, replace line breaks (the special character <code class="docutils literal notranslate"><span class="pre">&quot;\n&quot;</span></code>) and tabs (the special character <code class="docutils literal notranslate"><span class="pre">&quot;\t&quot;</span></code> with single spaces.</p></li>
<li><p>Create an empty string to hold the normalized text.</p></li>
<li><p>Loop over all the characters in the original string, and for each character, add to the normalized text only if it is a) an alphabetic character or b) a space, provided that the last element of the normalized string is not also a space. (This last condition ensures that we don’t end up with multiple contiguous spaces.)</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">return</span></code> keyword is necessary to make our new <code class="docutils literal notranslate"><span class="pre">text_norm</span></code> variable available in the context where we call the function.</p></li>
</ol>
<p>Then we call this function on the <code class="docutils literal notranslate"><span class="pre">g_text</span></code> variable, assigning the return value to the new variable <code class="docutils literal notranslate"><span class="pre">g_text_norm</span></code>. (Again, don’t dwell on the names; it’s common in programming to have multiple variables referring to the same value, where each variable belongs to a different context. It’s a technique that helps reduce bugs in programming and make programs more efficient.)</p>
<p>Finally, we look at the first 1,000 characters in our normalized text.</p>
</div>
<p>This method isn’t perfect, but we’ll trust that any errors – like the disappearance of accented characters from French proper nouns, etc. – will get smoothed over in the aggregate.</p>
</section>
<section id="setting-the-table">
<h4>Setting the table<a class="headerlink" href="#setting-the-table" title="Permalink to this heading">#</a></h4>
<p>To create our transition table of bigrams, we’ll define two new functions in Python. The first function, <code class="docutils literal notranslate"><span class="pre">create_ngrams</span></code>, generalizes a bit from our immediate use case; by setting the parameter called <code class="docutils literal notranslate"><span class="pre">n</span></code> in the function call to a number higher than 2, we can create combinations of three or more successive characters (trigrams, quadgrams, etc.). This feature will be useful a little later.</p>
<p>Run the code below to define the function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a series of ngrams out of the provided text argument. The argument n determines the size of each ngram; n must be greater than or equal to 2. </span>
<span class="sd">    Returns a list of ngrams, where each ngram is a Python tuple consisting of n characters.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">text_arrays</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">last_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">text_arrays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">last_index</span><span class="p">])</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">text_arrays</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<p>The code here might look a little cryptic, but it’s doing what we illustrated above: taking a single string (the <code class="docutils literal notranslate"><span class="pre">text</span></code> argument) and transforming it into multiple, parallel, strings, each of which is copy of the previous but shifted to the left by one character. (The shifted characters get lopped off, so that each string remains the same size as the others.)</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">range()</span></code> function just returns a list of numbers, from 0 up to <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p></li>
<li><p>For each value of <code class="docutils literal notranslate"><span class="pre">i</span></code> in our loop, we find the position of the string that is <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">i</span> <span class="pre">-</span> <span class="pre">1</span></code> characters from the end. We do this to ensure that the strings line up. So if <code class="docutils literal notranslate"><span class="pre">n</span></code> is 3, then the first time through the loop, <code class="docutils literal notranslate"><span class="pre">i</span></code> will be 0, and <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">i</span> <span class="pre">-</span> <span class="pre">1</span></code> will be <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p>Using Python’s string-slicing syntax, we take a portion of the string from <code class="docutils literal notranslate"><span class="pre">i</span></code> to the position calculated above. So on the first time through our loop, our new string will start at the 0 position (the first character) and end with the antepenulimate character.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">i</span></code> is 1, our new string will start at the 1 position (second character) and end with the penultimate character.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">i</span></code> is 2, our new string will start at the 2 position (third character) and end with the last character.</p></li>
</ul>
<p>A little reflection shows that all three of these strings will be of equal length.</p>
<p>Finally, we use the Python <code class="docutils literal notranslate"><span class="pre">zip()</span></code> function to align all three strings and separate them into groups of items that occupy the same position in each string, which you can visualize as follows:</p>
<p>[image]</p>
</div>
<p>Let’s illustrate our function with a small text first. The output is a Python list, which contains a series of additional collections (called tuples) nested within it. Each subcollection corresponds to a 2-character window, and the window is moved one character to the right each time.</p>
<p>This structure will allow us to create our transition table, showing which characters follow which other characters most often.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;abcdefghijklmnopqrstuvwxyz&#39;</span>
<span class="n">create_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run the code section below to define another function, <code class="docutils literal notranslate"><span class="pre">create_transition_table</span></code>, which does what its name suggests.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="k">def</span> <span class="nf">create_transition_table</span><span class="p">(</span><span class="n">ngrams</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Expects as input a list of tuples corresponding to ngrams.</span>
<span class="sd">    Returns a dictionary of dictionaries, where the keys to the outer dictionary consist of strings corresponding to the first n-1 elements of each ngram.</span>
<span class="sd">    The values of the outer dictionary are themselves dictionaries, where the keys are the nth elements each ngram, and the values are the frequence of occurrence.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ttable</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ngram</span><span class="p">[:</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ttable</span><span class="p">:</span>
            <span class="n">ttable</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">ttable</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">ngram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">ttable</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<ol class="arabic simple">
<li><p>Since the <code class="docutils literal notranslate"><span class="pre">create_transition_table</span></code> function expects a list of n-grams as its argument, we find the value of <code class="docutils literal notranslate"><span class="pre">n</span></code> by taking the length of the first element in the list.</p></li>
<li><p>We define a new dictionary, <code class="docutils literal notranslate"><span class="pre">ttable</span></code>, to hold our transitions.</p></li>
<li><p>We loop over the n-grams in our list.</p>
<ul class="simple">
<li><p>For every n-gram, we are going to separate it into the character in the nth position, and the sequence of characters from the first to the position <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code>. Thus, if <code class="docutils literal notranslate"><span class="pre">n</span></code> is 2, we separate the bigram into two characters. If <code class="docutils literal notranslate"><span class="pre">n</span></code> is 3, on the other hand, the first part consist of two characters. The second part will always be a single character, no matter the value of <code class="docutils literal notranslate"><span class="pre">n</span></code>. That’s because we’re still calculating the frequency of <em>individual characters</em>. We’re just basing that frequency on a certain window of characters to the immediate left of each character, and that window can have different sizes.</p></li>
<li><p>The first part of each n-gram is our dictionary <em>key</em>. Because we’re using a dictionary, we have to associate each key with a value.</p></li>
<li><p>However, unlike our first table of frequencies, the value of this key is actually another dictionary! That’s because any initial sequence of <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code> characters can be followed (in theory) by any other character. And it’s the frequency of the latter that we’re calculating. So assuming <code class="docutils literal notranslate"><span class="pre">n</span></code> is 3, we might have <code class="docutils literal notranslate"><span class="pre">th</span></code> followed by <code class="docutils literal notranslate"><span class="pre">e</span></code>, and <code class="docutils literal notranslate"><span class="pre">th</span></code> followed by <code class="docutils literal notranslate"><span class="pre">a</span></code>, and <code class="docutils literal notranslate"><span class="pre">th</span></code> followed by <code class="docutils literal notranslate"><span class="pre">o</span></code>, etc. And we’re interested in the frequency of each of those combinations.</p></li>
<li><p>If we haven’t seen this key before, we have to create its dictionary. For that, we use a special Python data structure called a <code class="docutils literal notranslate"><span class="pre">Counter</span></code>. The <code class="docutils literal notranslate"><span class="pre">Counter</span></code> just saves us the step of having to initialize every value to 0.</p></li>
<li><p>Finally, the line <code class="docutils literal notranslate"><span class="pre">ttable[key][ngram[-1]]</span> <span class="pre">+=</span> <span class="pre">1</span></code> increments the numeric value associated with a) the character in the nth position of the current n-gram, which is in turn associated with b) the sequence of characters in the first <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code> positions of the n-gram. So if the current value of <code class="docutils literal notranslate"><span class="pre">ngram</span></code> is <code class="docutils literal notranslate"><span class="pre">the</span></code>, then <code class="docutils literal notranslate"><span class="pre">key</span></code> is <code class="docutils literal notranslate"><span class="pre">th</span></code>, and <code class="docutils literal notranslate"><span class="pre">ngram[-1]</span></code> (which refers to the last character in <code class="docutils literal notranslate"><span class="pre">ngram</span></code>) is <code class="docutils literal notranslate"><span class="pre">e</span></code>. So that line translates to <code class="docutils literal notranslate"><span class="pre">ttable[&quot;th&quot;][&quot;e&quot;]</span> <span class="pre">+=</span> <span class="pre">1</span></code> (which increments the value, whatever it is, by 1).</p></li>
</ul>
</li>
</ol>
</div>
<p>Now run the code below to create the transition table for the bigrams in the alphabet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_transition_table</span><span class="p">(</span><span class="n">create_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Here our transition table consists of frequencies that are all 1, because (by definition) each letter occurs only once in the alphabet. The way to read the table, however, is as follows:</p>
<blockquote>
<div><p>The letter <code class="docutils literal notranslate"><span class="pre">b</span></code> occurs after the letter <code class="docutils literal notranslate"><span class="pre">a</span></code> 1 time in our (alphabet) sample.</p>
<p>The letter <code class="docutils literal notranslate"><span class="pre">c</span></code> occurs after the letter <code class="docutils literal notranslate"><span class="pre">b</span></code> 1 time in our sample.</p>
<p>…</p>
</div></blockquote>
<p>Now let’s use these functions to create the transition table with bigrams <em>Gargantua and Pantagruel</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_ttable</span> <span class="o">=</span> <span class="n">create_transition_table</span><span class="p">(</span><span class="n">create_ngrams</span><span class="p">(</span><span class="n">g_text_norm</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Our table will now be significantly bigger. But let’s use it see how frequently the letter <code class="docutils literal notranslate"><span class="pre">e</span></code> follows the letter <code class="docutils literal notranslate"><span class="pre">h</span></code> in our text:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_ttable</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">][</span><span class="s1">&#39;e&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can visualize our table fairly easily by using a Python library called <a class="reference external" href="https://pandas.pydata.org/">pandas</a>.</p>
<p>Run the code below, which may take a moment to finish.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.precision&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">g_ttable</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To read the table, select a row for the first letter, and then a column to find the frequency of the column letter appearing after the letter in the row. (In other words, read across then down.)</p>
<p>The space character appears as the empty column/row label in this table.</p>
</section>
</section>
<section id="automatic-writing">
<h3>Automatic writing<a class="headerlink" href="#automatic-writing" title="Permalink to this heading">#</a></h3>
<p>In Shannon’s* article, these kinds of transition tables are used to demonstrate the idea that English text can be effectively represented as a Markov chain. And to effect the demonstration, Shannon* presents the results of <em>generating</em> text by weighted random sampling from the transition tables.</p>
<p>To visualize how the weighted sampling works, imagine the following:</p>
<ol class="arabic simple">
<li><p>You choose a row at random on the transition table above, writing its character down on paper.</p></li>
<li><p>The numbers in that row correspond to the observed frequencies of characters following the character corresponding to that row.</p></li>
<li><p>You fill a big with Scrabble tiles, using as many tiles for each character as indicated by the corresponding cell in the selected row. If a cell has <code class="docutils literal notranslate"><span class="pre">NaN</span></code> in it – the null value – you don’t put any tiles of that chracter in the bag.</p></li>
<li><p>You draw one tile from the bag. You write down the character you just selected. This character indicates the next row on the table.</p></li>
<li><p>Using that row, you repeat steps 1 through 4. And so on, for however many characters you want to include in your sample.</p></li>
</ol>
<p>Run the code below to define a function that will do this sampling for us.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_sample</span><span class="p">(</span><span class="n">ttable</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Using a transition table of ngrams, creates a random sample of the provided length (default is 100 characters).</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">starting_chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">first_char</span> <span class="o">=</span> <span class="n">last_char</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">starting_chars</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_char</span><span class="p">)</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">first_char</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
        <span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="p">[</span><span class="n">last_char</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="p">[</span><span class="n">last_char</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">next_char</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">chars</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">generated_text</span> <span class="o">+=</span> <span class="n">next_char</span>
        <span class="n">last_char</span> <span class="o">=</span> <span class="n">generated_text</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">generated_text</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<p>Our function expects a transition table as its first argument (a dictionary of dictionaries) and an optional number as its second argument. If not <code class="docutils literal notranslate"><span class="pre">length</span></code> is provided, 100 (characters) is used as the default.</p>
<ol class="arabic simple">
<li><p>We randomly select one element from among the keys of the outer dictionary (the rows of the transition table). For clarity’s sake, we assign this element to <em>two</em> variable: <code class="docutils literal notranslate"><span class="pre">first_char</span></code> and <code class="docutils literal notranslate"><span class="pre">last_char</span></code>. We will update the <code class="docutils literal notranslate"><span class="pre">last_char</span></code> variable throughout the process, to keep track of the last character(s) we have generated, which determine the selection of the next character.</p></li>
<li><p>Note that <code class="docutils literal notranslate"><span class="pre">first_char</span></code> and <code class="docutils literal notranslate"><span class="pre">last_char</span></code> may or may not be a single character; that depends on the size of the n-grams represented by the provided transition table (<code class="docutils literal notranslate"><span class="pre">ttable</span></code>).</p></li>
<li><p>We find the length of <code class="docutils literal notranslate"><span class="pre">first_char</span></code> and assign it to variable, <code class="docutils literal notranslate"><span class="pre">l</span></code>.</p></li>
<li><p>We initialize a new string, <code class="docutils literal notranslate"><span class="pre">generated_text</span></code>, to this randomly selected element.</p></li>
<li><p>We loop over the numbers up the value of <code class="docutils literal notranslate"><span class="pre">length</span></code>: basically, just performing the same action <code class="docutils literal notranslate"><span class="pre">length</span></code> times.</p></li>
<li><p>For each iteration, we use <code class="docutils literal notranslate"><span class="pre">last_char</span></code> (the first part of an n-gram, as derived in the <code class="docutils literal notranslate"><span class="pre">create_transition_table</span></code> function) to select the list of characters that follow <code class="docutils literal notranslate"><span class="pre">last_char</span></code> in the source text and their frequencies of occurrence.</p></li>
<li><p>We randomly select a single character, using the frequencies as weights.</p></li>
<li><p>We add that character to <code class="docutils literal notranslate"><span class="pre">generated_text</span></code>.</p></li>
<li><p>We update <code class="docutils literal notranslate"><span class="pre">last_char</span></code> to reflect the last <code class="docutils literal notranslate"><span class="pre">l</span></code> characters, which again, correspond to the first part of each n-gram.</p></li>
</ol>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_sample</span><span class="p">(</span><span class="n">g_ttable</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run the code above a few times for the full effect. It’s still nonsense, but maybe it seems more like recognizable nonsense – meaning nonsense that a human being who speaks English might make up – compared with our previous randomly generated examples. If you agree that it’s more recognizable, can you pinpoint features or moments that make it so?</p>
<p>Personally, it reminds me of the outcome of using a Ouija board: recognizable words almost emerging from some sort of pooled subconscious, then sinking back into the murk before we can make any sense out of them.</p>
<section id="more-silly-walks">
<h4>More silly walks<a class="headerlink" href="#more-silly-walks" title="Permalink to this heading">#</a></h4>
<p>More adept Ouija-board users can be simulated by increasing the size of our n-grams. As Shannon’s* article demonstrates, the approximation to the English lexicon increases by moving from bigrams to trigrams – such that frequencies are calculated in terms of the occurrence of a given letter immediately after a pair of letters.</p>
<p>So instead of a table like this:</p>
<a class="reference internal image-reference" href="_images/bigram-table.png"><img alt="A table with the letters &quot;h,&quot; a space, &quot;o,&quot; &quot;e,&quot; and &quot;i&quot; along the top (column headers), and &quot;t,&quot; space, &quot;c,&quot; &quot;w,&quot; &quot;s,&quot; and &quot;g&quot; along the left-hand side (row labels), and numbers in the cells of the table." src="_images/bigram-table.png" style="width: 300px;" /></a>
<p>we have this (where the <code class="docutils literal notranslate"><span class="pre">h</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, and <code class="docutils literal notranslate"><span class="pre">w</span></code> in the row labels are all preceded by the space character):</p>
<a class="reference internal image-reference" href="_images/bigram-table-2.png"><img alt="A table with the letters &quot;e,&quot; &quot;a,&quot; space, &quot;i,&quot; &quot;o&quot; along the top (column headers), and &quot;th,&quot; space &quot;h&quot;, space &quot;b&quot;,&quot; &quot;er,&quot; and space &quot;w&quot; along the left-hand side (row labels), and numbers in the cells of the table." src="_images/bigram-table-2.png" style="width: 300px;" /></a>
<p>Note, however, that throughout these experiments, the level of approximation to any particular understanding of “the English lexicon” depends on the nature of the data from which we derive our frequencies. Urquhart’s translation of Rabelais, dating from the 16th Century, has a rather distinctive vocabulary, as you might expect, even with the modernized spelling and grammar of the Project Gutenberg edition.</p>
<p>The code below defines some interactive controls to make our experiments easier to manipulate. Run both sections of code to create the controls.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="k">def</span> <span class="nf">create_slider</span><span class="p">(</span><span class="n">min_value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span>
            <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="nb">min</span><span class="o">=</span><span class="n">min_value</span><span class="p">,</span>
            <span class="nb">max</span><span class="o">=</span><span class="n">max_value</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Set value of n:&#39;</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">create_update_function</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">transition_function</span><span class="p">,</span> <span class="n">slider</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    returns a callback function for use in updating the provided transition table with ngrams from text, given slider.value, as well as an output widget</span>
<span class="sd">    for displaying the output of the callback</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">on_update</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
            <span class="k">global</span> <span class="n">ttable</span>
            <span class="n">ttable</span> <span class="o">=</span> <span class="n">transition_function</span><span class="p">(</span><span class="n">create_ngrams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">slider</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Updated! Value of n is now </span><span class="si">{</span><span class="n">slider</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">on_update</span><span class="p">,</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">create_generate_function</span><span class="p">(</span><span class="n">sample_function</span><span class="p">,</span> <span class="n">slider</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    returns a callback function for use in generating new random samples from the provided trasition table.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">on_generate</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;(n=</span><span class="si">{</span><span class="n">slider</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s1">) </span><span class="si">{</span><span class="n">sample_function</span><span class="p">(</span><span class="n">ttable</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">on_generate</span><span class="p">,</span> <span class="n">output</span>
    
<span class="k">def</span> <span class="nf">create_button</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a new button with the provided label, and sets its click handler to the provided callback function</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">button</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ttable</span> <span class="o">=</span> <span class="n">g_ttable</span>
<span class="n">ngram_slider</span> <span class="o">=</span> <span class="n">create_slider</span><span class="p">()</span>
<span class="n">update_callback</span><span class="p">,</span> <span class="n">update_output</span> <span class="o">=</span> <span class="n">create_update_function</span><span class="p">(</span><span class="n">g_text_norm</span><span class="p">,</span> <span class="n">create_transition_table</span><span class="p">,</span> <span class="n">ngram_slider</span><span class="p">)</span>
<span class="n">update_button</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;Update table&quot;</span><span class="p">,</span> <span class="n">update_callback</span><span class="p">)</span>
<span class="n">generate_callback</span><span class="p">,</span> <span class="n">generate_output</span> <span class="o">=</span> <span class="n">create_generate_function</span><span class="p">(</span><span class="n">create_sample</span><span class="p">,</span> <span class="n">ngram_slider</span><span class="p">)</span>
<span class="n">generate_button</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;New sample&quot;</span><span class="p">,</span> <span class="n">generate_callback</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">ngram_slider</span><span class="p">,</span> <span class="n">update_button</span><span class="p">,</span> <span class="n">update_output</span><span class="p">,</span> <span class="n">generate_button</span><span class="p">,</span> <span class="n">generate_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Use the slider above to change the value of <code class="docutils literal notranslate"><span class="pre">n</span></code>. Click <code class="docutils literal notranslate"><span class="pre">Update</span> <span class="pre">table</span></code> to recreate the transition table using the new value of <code class="docutils literal notranslate"><span class="pre">n</span></code>. Then use the <code class="docutils literal notranslate"><span class="pre">New</span> <span class="pre">sample</span></code> button to generate a new, random sample of text from the transition table. You can generate as many samples as you like, and you can update the size of the ngrams in between in order to compare samples of different sizes.</p>
<div class="dropdown admonition">
<p class="admonition-title">Reading the code</p>
<p>The code above uses a special Python library (a bundle of Python code) to create some HTML elements with which to interact with the code we’ve already written.</p>
<p>We haven’t changed the underlying alogorithm at all – we’ve just modified the interface to make it easier to experiment with different values of <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
</div>
<p>What do you notice about the effect of higher values of <code class="docutils literal notranslate"><span class="pre">n</span></code> on the nature of the random samples produced?</p>
</section>
</section>
<section id="a-rabelaisian-chatbot">
<h3>A Rabelaisian chatbot<a class="headerlink" href="#a-rabelaisian-chatbot" title="Permalink to this heading">#</a></h3>
<p>Following Shannon’s* article, we can observe the same phenomena using whole words to create our n-grams. I find such examples more compelling, perhaps because I find it easier or more fun to look for the glimmers of sense of random strings of words than in random strings of letters, which may or may not be recognizable words.</p>
<p>But the underlying procedure is the same. We first create a list of “words” out of our normalized text by splitting the latter on the occurrences of white space. As a result, instead of a single string containing the entire text, we’ll have a Python list of strings, each of which is a word from the orginal text.</p>
<p>Note that this process is not a rigorous way of tokenizing a text. If that is your goal – to split a text into words, in order to employ word-frequency analysis or similar techniques – there are very useful <a class="reference external" href="https://spacy.io/">Python libraries</a> for this task, which use sophisticated tokenizing techniques.</p>
<p>For purposes of our experiment, however, splitting on white space will suffice.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_text_words</span> <span class="o">=</span> <span class="n">g_text_norm</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>From here, we can create our ngrams and transition table as before. First, we just need to modify our previous code to put the spaces back (since we took them out in order to create our list of words).</p>
<p>Run the code sections below to create some new functions, and the to create some more HTML controls for these functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_ttable_words</span><span class="p">(</span><span class="n">ngrams</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Expects as input a list of tuples corresponding to ngrams.</span>
<span class="sd">    Returns a dictionary of dictionaries, where the keys to the outer dictionary consist of strings corresponding to the first n-1 elements of each ngram.</span>
<span class="sd">    The values of the outer dictionary are themselves dictionaries, where the keys are the nth elements each ngram, and the values are the frequence of occurrence.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ttable</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">ngram</span><span class="p">[:</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ttable</span><span class="p">:</span>
            <span class="n">ttable</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">ttable</span><span class="p">[</span><span class="n">key</span><span class="p">][(</span><span class="n">ngram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">ttable</span>
    
<span class="k">def</span> <span class="nf">create_sample_words</span><span class="p">(</span><span class="n">ttable</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Using a transition table of ngrams, creates a random sample of the provided length (default is 100 characters).</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">starting_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">first_words</span> <span class="o">=</span> <span class="n">last_words</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">choices</span><span class="p">(</span><span class="n">starting_words</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_words</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">first_words</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
        <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="p">[</span><span class="n">last_words</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ttable</span><span class="p">[</span><span class="n">last_words</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">next_word</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_word</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">last_words</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:])</span>
    <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ttable</span> <span class="o">=</span> <span class="n">create_ttable_words</span><span class="p">(</span><span class="n">create_ngrams</span><span class="p">(</span><span class="n">g_text_words</span><span class="p">))</span>
<span class="n">ngram_slider_w</span> <span class="o">=</span> <span class="n">create_slider</span><span class="p">()</span>
<span class="n">update_callback_w</span><span class="p">,</span> <span class="n">update_output_w</span> <span class="o">=</span> <span class="n">create_update_function</span><span class="p">(</span><span class="n">g_text_words</span><span class="p">,</span> <span class="n">create_ttable_words</span><span class="p">,</span> <span class="n">ngram_slider_w</span><span class="p">)</span>
<span class="n">update_button_w</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;Update table&quot;</span><span class="p">,</span> <span class="n">update_callback_w</span><span class="p">)</span>
<span class="n">generate_callback_w</span><span class="p">,</span> <span class="n">generate_output_w</span> <span class="o">=</span> <span class="n">create_generate_function</span><span class="p">(</span><span class="n">create_sample_words</span><span class="p">,</span> <span class="n">ngram_slider_w</span><span class="p">)</span>
<span class="n">generate_button_w</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;New sample&quot;</span><span class="p">,</span> <span class="n">generate_callback_w</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">ngram_slider_w</span><span class="p">,</span> <span class="n">update_button_w</span><span class="p">,</span> <span class="n">update_output_w</span><span class="p">,</span> <span class="n">generate_button_w</span><span class="p">,</span> <span class="n">generate_output_w</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Use the slider and buttons above to generate sample text for various values of <code class="docutils literal notranslate"><span class="pre">n</span></code>. Samples are based on n-grams of words from the source text.</p>
</section>
<section id="how-drunken-was-our-walk">
<h3>How drunken was our walk?<a class="headerlink" href="#how-drunken-was-our-walk" title="Permalink to this heading">#</a></h3>
<p>In his article, Shannon* reports various results of these experiments, using different values for <code class="docutils literal notranslate"><span class="pre">n</span></code> with both letter- and word-frequencies. He includes the following sample, apparently produced at random with word bigrams, though he does not disclose the particular textual sources from which he derived his transition tables:</p>
<blockquote>
<div><p>THE HEAD AND IN FRONTAL ATTACK ON AN ENGLISH WRITER THAT THE CHARACTER OF THIS POINT IS THEREFORE ANOTHER METHOD FOR THE LETTERS THAT THE TIME OF WHOEVER TOLD THE PROBLEM FOR AN UNEXPECTED.</p>
</div></blockquote>
<p>I’ve always thought that Shannon’s* example seems suspiciously fortuitous, given its mention of attacks on English writers and methods for letters, etc. Who knows how many trials he made before he got this result (assuming he didn’t fudge anything). All the same, one of the enduring charms of the “Markov text generator” is its propensity to produce uncanny stretches of text that, as Shannon* writes, sound “not at all unreasonable.”</p>
<p>A question does arise: how novel are these stretches? In other words, what proportion of the generated sample is unique relative to the source? One way approach to the question is to think in terms of unique n-grams. When using a value of 3 for <code class="docutils literal notranslate"><span class="pre">n</span></code>, by definition every three-word sequence in our generated sample will match some sequence in the source text. But what about sequences of 4 words? Just looking at the samples we’ve created, it’s clear that at least some of these are novel, since some are plainly nonsense and not likely to appear in Rabelais’ text.</p>
<p>We might measure their novelty by creating a lot of samples and then, for each sample, calculating the percentage of 4-word n-grams that are <em>not</em> in the source text. Running this procedure over 1,000 samples, I arrive at an average of 40% – so a little less than half of all the 4-word sequences across all the samples are sequences that do <em>not</em> appear in Rabelais’ text.</p>
<p>As for what percentage of those constitute phrases that are not “unreasonable” as spontaneous English utterances, that’s a question that’s hard to answer computationally. Obviously, it depends in part on your definition of “not unreasonable.” But it’s kind of fun to pick out phrases of length <code class="docutils literal notranslate"><span class="pre">n+1</span></code> (or <code class="docutils literal notranslate"><span class="pre">n+2</span></code>, etc.) from your sample and see if they appear in the original. You can do so by running code like the following. Just edit the part between the quotation marks so that they contain a phrase from your sample. If Python returns <code class="docutils literal notranslate"><span class="pre">True</span></code>, the phrase is <em>not</em> in the source.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;to do a little untruss&#39;</span> <span class="ow">in</span> <span class="n">g_text_norm</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition">
<p class="admonition-title">How did I do it?</p>
<p>For those interested in such details, the following is the Python code I used to arrive at my estimate of 40% novelty for phrases of length <code class="docutils literal notranslate"><span class="pre">n+1</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> was 3, using words, not letters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_unique</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">text_sample</span> <span class="o">=</span> <span class="n">create_sample</span><span class="p">(</span><span class="n">g_ttable</span><span class="p">)</span>
    <span class="n">ngrams_sample</span> <span class="o">=</span> <span class="n">create_ngrams</span><span class="p">(</span><span class="n">text_sample</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">this_num</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">ngrams_sample</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ngram</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">g_text_norm</span><span class="p">:</span>
            <span class="n">this_num</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">num_unique</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">this_num</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams_sample</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">num_unique</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">num_unique</span><span class="p">))</span>
</pre></div>
</div>
<p>The code creates a loop that runs 1,000 times. On each iteration, it creates a new randomized sample from the transition table (defined, as mentioned, with n-grams of size <code class="docutils literal notranslate"><span class="pre">n=3</span></code>). Then it creates n-grams out of the sample, using <code class="docutils literal notranslate"><span class="pre">n=4</span></code>. For each n-gram of size 4 in the sample, it checks whether this exact sequence of words appears in the source text. If it does not, then the score for the current sample is incremented by one. For each sample, a final score is derived by dividing the total number of unique n-grams by the total number of n-grams in the sample. Finally, an average score across all 1,000 samples is calculated. This average score represents the average amount of “uniqueness” in these samples for sequences of length <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">+</span> <span class="pre">1</span></code> (where <code class="docutils literal notranslate"><span class="pre">n</span></code> is, again, the size of the n-grams used to create the transition table for the Markov chains).</p>
</div>
</section>
<section id="where-lies-the-labor">
<h3>Where lies the labor?<a class="headerlink" href="#where-lies-the-labor" title="Permalink to this heading">#</a></h3>
<p>The code in this notebook implements a kind of algorithm, albeit a simple one. A great many procedures, now standard parts of computer applications – e.g., efficiently sorting a list – involve more logical complexity. Our Markovian model of Rabelais’ novel seems almost <em>too</em> simple to produce the results it does, which is perhaps partly why the results can feel uncanny.</p>
<p>And while it needs a gargantuan leap to get from our rudimentary text machine to Chat GPT, the large-language model behind the latter is, like ours, a statistical representation of patterns occurring in the textual data on which it is based. The novelty of the latest models derives from their capacity to encode overlapping contexts: to represent how the units that make up text occur in multiple relations to each other: e.g., to capture, mathematically, the fact that a certain word frequently follows another word but often appears in the same sentence or paragraph as a third word, and so on.<a class="footnote-reference brackets" href="#id30" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> This complexity of representation, coupled with the sheer size of the data used to train the model, leads to Chat-GPT’s uncanny ability to mimic textual genres with a high degree of stylistic fidelity.<a class="footnote-reference brackets" href="#id32" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a></p>
<p>But perhaps we do Rabelais’ text a disservice by calling it the “data” behind our model. We could, just as reasonably, speak of the text itself as the model – likewise for the tera- or petabytes of text used to train Chat-GPT and its ilk. On Shannon’s* theory, language encodes information. The ultimate aim of the theory is to find the most <em>efficient</em> means of encoding (in order to solve “the engineering problem” of modern telecommunications networks); nonetheless, the success of the theory implies that any use of language (any use recognizable as such by users of the language) <em>already</em> encodes information. In other words, the transition probabilities we generated from Rabelais’ text are already expressed by Rabelais’ text; our transition matrix just encodes that information in a more computationally tractable form. Every text encodes its producer’s “knowledge of the statistics of the language” (in Shannon’s* words). And one might argue that every text encodes its readers’ knowledge, too. It’s on the basis of such knowledge that we can “decode” Rabelais’ novel, as well as the stochastic quasi-nonsense we can generate on its basis, which feels, relative to the former, like an excess of sense (an excess over and above Rabelais’ already excessive text), spilling over the top.</p>
<section id="further-experiments">
<h4>Further experiments<a class="headerlink" href="#further-experiments" title="Permalink to this heading">#</a></h4>
<p>To see how differences in the source of the model impact the result, try running our code on different texts. As written, our code only works on plain text format (files with a <code class="docutils literal notranslate"><span class="pre">.txt</span></code> extension). <a class="reference external" href="https://www.gutenberg.org/">Project Gutenberg</a> is a good source for these – just make sure that you choose the <code class="docutils literal notranslate"><span class="pre">Plain</span> <span class="pre">Text</span> <span class="pre">UTF-8</span></code> option for displaying a given text. You can copy the URL for the plain text either from your browser’s address bar (if the text opens as a separate tab or page), or by right-clicking on the <code class="docutils literal notranslate"><span class="pre">Plaint</span> <span class="pre">Text</span> <span class="pre">UTF-8</span></code> link and selecting the option <code class="docutils literal notranslate"><span class="pre">Copy</span> <span class="pre">Link</span></code>.</p>
<p>The following code creates a text box into which you can paste the link.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url_box</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span>
    <span class="n">value</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">placeholder</span><span class="o">=</span><span class="s1">&#39;Type something&#39;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;URL:&#39;</span><span class="p">,</span>
    <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>   
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The big block of code below re-uses code from above to download and normalize the text at the provided URL, create a transition table of words from the text, and present options for changing the value of N and for generating new samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">url_box</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
    <span class="n">text_file</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url_box</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">text_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">norm_text_words</span> <span class="o">=</span> <span class="n">normalize_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">ttable</span> <span class="o">=</span> <span class="n">create_ttable_words</span><span class="p">(</span><span class="n">create_ngrams</span><span class="p">(</span><span class="n">norm_text_words</span><span class="p">))</span>
    <span class="n">ngram_slider_new</span> <span class="o">=</span> <span class="n">create_slider</span><span class="p">()</span>
    <span class="n">update_callback_new</span><span class="p">,</span> <span class="n">update_output_new</span> <span class="o">=</span> <span class="n">create_update_function</span><span class="p">(</span><span class="n">norm_text_words</span><span class="p">,</span> <span class="n">create_ttable_words</span><span class="p">,</span> <span class="n">ngram_slider_new</span><span class="p">)</span>
    <span class="n">update_button_new</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;Update table&quot;</span><span class="p">,</span> <span class="n">update_callback_new</span><span class="p">)</span>
    <span class="n">generate_callback_new</span><span class="p">,</span> <span class="n">generate_output_new</span> <span class="o">=</span> <span class="n">create_generate_function</span><span class="p">(</span><span class="n">create_sample_words</span><span class="p">,</span> <span class="n">ngram_slider_new</span><span class="p">)</span>
    <span class="n">generate_button_new</span> <span class="o">=</span> <span class="n">create_button</span><span class="p">(</span><span class="s2">&quot;New sample&quot;</span><span class="p">,</span> <span class="n">generate_callback_new</span><span class="p">)</span>
    <span class="n">display</span><span class="p">(</span><span class="n">ngram_slider_new</span><span class="p">,</span> <span class="n">update_button_new</span><span class="p">,</span> <span class="n">update_output_new</span><span class="p">,</span> <span class="n">generate_button_new</span><span class="p">,</span> <span class="n">generate_output_new</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="carnival-intelligence">
<h3>Carnival intelligence?<a class="headerlink" href="#carnival-intelligence" title="Permalink to this heading">#</a></h3>
<p>Lacan famously said that the unconscious is structured like a language. Whether that’s an apt description of the human psyche is at least debatable. But might we say that these models manifest the unconscious structures of language itself? We can catch glimpses of this manifestation in the relatively humble outcome of Shannon’s* experiments: in the Markovian leaps that lead us to make <em>sense</em> out of patterned randomness, leaps which, at the same time, reveal the nonsense that riots on the other side of sense. These experiments allow us to wander through spaces of grammatical, lexical, and stylistic possibility – and the pleasure they offer, for me, lies in their letting us stumble into places where our rule-observant habits might not otherwise let us go.</p>
<p>What if we were to approach generative AI in the same spirit? Not as the <em>deus ex machina</em> that will save the world (which it almost certainly is not), and not only as a technology that will further alienate and oppress our labor (which it very probably is). But to borrow from Bakhtin, as a carnivalesque mirror of our collective linguistic unconscious: like carnival, offering a sense of freedom from restraint that is, at the same time, the affirmation, by momentary inversion, of the prevailing order of things. But also a reminder that language is the repository of an intelligence neither of the human (considered as an isolated being), nor of the machine, but of the collective, and that making sense is always a political act (<span id="id15">[<a class="reference internal" href="bibliography.html#id7" title="M. M. Bakhtin. Rabelais and his world. Indiana University Press, Bloomington, 1st midland book ed. edition, 1984. ISBN 978-0-253-20341-0.">Bak84</a>]</span>).</p>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id16" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>In the late nineteenth and early twentieth centuries, computation in the West became increasingly gendered as women’s work; on this history, see <span id="id17">[<a class="reference internal" href="bibliography.html#id2" title="David Alan Grier. When Computers Were Human. Princeton University Press, Princeton, NJ, 2013. ISBN 978-1-306-04618-3 978-1-4008-4936-9.">Gri13</a>]</span>. This division of labor developed out of the long-standing European prejudice that drew a hard line between computation and supposedly “higher” forms of mathematical reasoning – a prejudice, as Jeffrey Binder (<span id="id18">[<a class="reference internal" href="bibliography.html#id8" title="Jeffrey M. Binder. Language and the rise of the algorithm. The University of Chicago Press, Chicago ;, 2022. ISBN 978-0-226-82253-2.">Bin22</a>]</span>) notes, that originally consigned algebra (with its roots in Arab mathematics and its favor among merchants) to an inferior intellectual status vis-a-vis geometry, which claimed a classical pedigree and was associated with the rigors of formal proof. Likewise, the industrialization of artificial intelligence (AI) hearkens back to the notion of the laborer, and especially the enslaved laborer and/or servant, as an <em>instrumentum vocale</em> (speaking machine), a concept inherited from classical antiquity but revived in early modern liberal theory by Locke and others (<span id="id19">[<a class="reference internal" href="bibliography.html#id4" title="Domenico Losurdo. Liberalism: a counter-history. Verso Books, London ;, 2011. ISBN 978-1-84467-693-4.">Los11</a>]</span>). If the rise of <em>literal</em> speaking machines occasions anxieties about the future of work, it also invites us to think about the cultural inheritance – an inheritance acutely alive in societies like the US – that regards the most socially necessary labor as a strictly “mechanical” exercise.</p>
</aside>
<aside class="footnote brackets" id="id20" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>On the conceptual history of the algorithm and its preciptation out of the discourses of philosophy, philology, and mathematics, see <span id="id21">[<a class="reference internal" href="bibliography.html#id8" title="Jeffrey M. Binder. Language and the rise of the algorithm. The University of Chicago Press, Chicago ;, 2022. ISBN 978-0-226-82253-2.">Bin22</a>]</span>. Even within the discipline of computer science, the rhetorical valence of the term <em>algorithm</em> is, as Binder demonstrates, hardly free from ambiguity. However, popular notions continue to frame the algorithm, and computation writ large, as a set “of procedures […] thought of as mathematical entities that exist apart from the complexities of the languages in which they are described and the concrete situations in which they are used.” And this framing serves, in Binder’s words, “as a levee holding back the social complexity of language […].” I follow Binder in thinking that this frame proves wholly inadequate to the challenges posed by generative AI like Chat-GPT.</p>
</aside>
<aside class="footnote brackets" id="id22" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>The phrase “unreasonable effectiveness” has circulated widely in recent years in relation to the capabilities of machine-learning models trained on large datasets, and especially those models derived from “deep” neural networks; the phrase apparently originates in <span id="id23">[<a class="reference internal" href="bibliography.html#id10" title="Eugene P. Wigner. The unreasonable effectiveness of mathematics in the natural sciences. Richard courant lecture in mathematical sciences delivered at New York University, May 11, 1959. Communications on Pure and Applied Mathematics, 13(1):1–14, February 1960. URL: https://onlinelibrary.wiley.com/doi/10.1002/cpa.3160130102 (visited on 2024-01-28), doi:10.1002/cpa.3160130102.">Wig60</a>]</span>, where it characterizes a claim about the mathematicization of the natural sciences.</p>
</aside>
<aside class="footnote brackets" id="id24" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">4</a><span class="fn-bracket">]</span></span>
<p>The asterisk beside Shannon’s name throughout this document is meant to acknowledge the silenced presence in the historical record of Shannon’s “closest collaborator,” his wife, Betty Shannon. Although I’m not aware of evidence that she collaborated with Claude on his famous article of 1948, she was am accomplished mathematician in her own right, and the evidence suggests that after their marriage in 1949, the Shannons worked together on many of the projects for which Claude Shannon would gain renown. See <span id="id25">[<a class="reference internal" href="bibliography.html#id13" title="Jimmy Soni and Rob Goodman. Betty Shannon, Unsung Mathematical Genius. July 2017. URL: https://blogs.scientificamerican.com/voices/betty-shannon-unsung-mathematical-genius/ (visited on 2024-02-12).">SG17</a>]</span>. Like many women in the history of computing, Betty Shannon’s contributions have disappeared into the background behind the attention lavished on white men and “their” machines.</p>
</aside>
<aside class="footnote brackets" id="id26" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">5</a><span class="fn-bracket">]</span></span>
<p>Examples of Python notebooks deployed in the digital humanities include Melanie Walsh’s online course <a class="reference external" href="https://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.html">Introduction to Cultural Analytics &amp; Python</a>, lessons on the <a class="reference external" href="https://programminghistorian.org/en/lessons/">Programming Historian</a> website, and tutorials from the <a class="reference external" href="https://github.com/ithaka/constellate-notebooks">JSTOR Constellate</a> project.</p>
</aside>
<aside class="footnote brackets" id="id27" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">6</a><span class="fn-bracket">]</span></span>
<p>The term “natural language,” when used in computational contexts, implies a distinction from “artificial” languages, i.e., programming languages. The term proliferates in the discourse about machine learning and AI because such approaches are increasingly focused on the analysis, manipulation, and simulation of human-authored text and human-embodied speech, where one of the goals is to reduce or dispense with the need for extra-computational processing or encoding. Requiring users to translate their commands into the idiom of the computing interface is an example of such encoding. However, the upsurge of interest in <a class="reference external" href="https://en.wikipedia.org/wiki/Prompt_engineering">prompt engineering</a> either indicates that AI has a long way to go in this respect, or else reminds us that even “natural” languages impose burdens of translation and mediation upon their users. Thus, I use the term “natural language” advisedly, but in what follows, I dispense with the scare quotes in the interest of a cleaner textual interface.</p>
</aside>
<aside class="footnote brackets" id="id28" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">7</a><span class="fn-bracket">]</span></span>
<p>In Shannon’s* own words, his investigtion sought to understand “the effect of statistical knowledge about the source in reducing the required capacity of the channel, by the use of proper encoding of information” (<span id="id29">[<a class="reference internal" href="bibliography.html#id3" title="C.E. Shannon. A mathematical theory of communication. The Bell System Technical Journal, 27(3-4):379–423, 623–656, July 1948. doi:10.1002/j.1538-7305.1948.tb01338.x.">Sha48</a>]</span>).</p>
</aside>
<aside class="footnote brackets" id="id30" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">8</a><span class="fn-bracket">]</span></span>
<p>In an article from 1950, Shannon* reports on the results of experiments conducted with Betty Shannon, in which they used statistical methods to study “the predictability of English” through performance on a textual guessing game. The study purports to reveal “long range statistics, influences extending over phrases, sentences, etc,” and it starts from the premise that “anyone speaking a language possesses, implicitly, an enormous knowledge of the statistics of the language.” The language model in this instance belongs to a human being, not a computer. But its attention to statistical effects that extend beyond the immediacy of the n-gram anticipates the design of today’s large-language models. <span id="id31">[<a class="reference internal" href="bibliography.html#id14" title="Claude Elwood Shannon. Prediction and Entropy of Printed English. In Neil James Alexander Sloane and Aaron D. Wyner, editors, Claude Elwood Shannon: collected papers, pages 194–208. IEEE press, New York, 1993.">Sha93</a>]</span>.</p>
</aside>
<aside class="footnote brackets" id="id32" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">9</a><span class="fn-bracket">]</span></span>
<p>It’s also the feature that has led some of their critics to call these models “stochastic parrots”(<span id="id33">[<a class="reference internal" href="bibliography.html#id6" title="Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21, 610–623. New York, NY, USA, March 2021. Association for Computing Machinery. URL: https://doi.org/10.1145/3442188.3445922 (visited on 2022-10-28), doi:10.1145/3442188.3445922.">BGMMS21</a>]</span>). And it may explain the difficulty of putting safeguards in place against the generation of hate speech, fake news, false citations, etc. These sorts of safeguards may even prove more technically challenging to implement than the models themselves.</p>
</aside>
</section>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="right-next"
       href="bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">References</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-linguistic-unconscious-of-ai">Exploring the Linguistic Unconscious of AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-two-ways-of-thinking-about-computation">Introduction: Two ways of thinking about computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-kinds-of-coding">Two kinds of coding</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#programs-as-code-s">Programs as code(s)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#baby-steps-in-python">Baby steps in Python</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-text">Encoding text</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#representing-text-in-python">Representing text in Python</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-chance">Language &amp; chance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-long-history-of-code">The long history of code</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-spate-of-tedious-counting">A spate of tedious counting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#random-writing">Random writing</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-difference-a-space-makes">The difference a space makes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#law-abiding-numbers">Law-abiding numbers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-as-a-drunken-walk">Language as a drunken walk</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-tedious-counting">More tedious counting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-text">Preparing the text</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-table">Setting the table</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-writing">Automatic writing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-silly-walks">More silly walks</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-rabelaisian-chatbot">A Rabelaisian chatbot</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-drunken-was-our-walk">How drunken was our walk?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#where-lies-the-labor">Where lies the labor?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#further-experiments">Further experiments</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#carnival-intelligence">Carnival intelligence?</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dolsy Smith & Holly Dugan
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>